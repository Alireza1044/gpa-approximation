{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'data/Elearning-Data-cut.xls'\n",
    "train_data_count = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input():\n",
    "    input = pd.read_excel(input_path, 0)\n",
    "    input = input.drop(['STUDENTN'], axis=1)\n",
    "    input = input.fillna(0)\n",
    "    output_gpa = pd.read_excel(input_path, 1)\n",
    "    output_fail = pd.read_excel(input_path, 2)[['OUT_IN']]\n",
    "    return input, output_gpa, output_fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input, output_gpa, output_fail = read_input()\n",
    "input = input.to_numpy()\n",
    "output_gpa = output_gpa.to_numpy()\n",
    "output_fail = output_fail.to_numpy()\n",
    "input2 = []\n",
    "output_fail2 = []\n",
    "\n",
    "for i in range(len(input)):\n",
    "    if output_fail[i] == 0:\n",
    "        input2.append(input[i])\n",
    "        input2.append(input[i])\n",
    "        output_fail2.append([output_fail[i][0]])\n",
    "        output_fail2.append([output_fail[i][0]])\n",
    "    else:\n",
    "        input2.append(input[i])\n",
    "        output_fail2.append([output_fail[i][0]])\n",
    "        \n",
    "input2 = np.array(input2)\n",
    "output_fail2 = np.array(output_fail2)\n",
    "\n",
    "X_train = input[:train_data_count]\n",
    "X_train2 = input2[:train_data_count]\n",
    "\n",
    "Y_train = output_gpa[:train_data_count]\n",
    "Y_train2 = output_fail2[:train_data_count]\n",
    "\n",
    "X_test = input[train_data_count:]\n",
    "X_test2 = input2[train_data_count:]\n",
    "\n",
    "Y_test = output_gpa[train_data_count:]\n",
    "Y_test2 = output_fail2[train_data_count:]\n",
    "Y_test22 = output_fail[train_data_count:]\n",
    "\n",
    "# X_train = keras.utils.normalize(X_train)\n",
    "# X_test = keras.utils.normalize(X_test)\n",
    "# X_test2 = keras.utils.normalize(X_test2)\n",
    "# X_train2 = keras.utils.normalize(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "500/500 [==============================] - 0s 377us/step - loss: 25.0082 - mse: 25.0082\n",
      "Epoch 2/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 6.8109 - mse: 6.8109\n",
      "Epoch 3/150\n",
      "500/500 [==============================] - 0s 57us/step - loss: 5.4612 - mse: 5.4612\n",
      "Epoch 4/150\n",
      "500/500 [==============================] - 0s 58us/step - loss: 4.1578 - mse: 4.1578\n",
      "Epoch 5/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 4.9598 - mse: 4.9598\n",
      "Epoch 6/150\n",
      "500/500 [==============================] - 0s 64us/step - loss: 3.5371 - mse: 3.5371\n",
      "Epoch 7/150\n",
      "500/500 [==============================] - 0s 61us/step - loss: 3.8324 - mse: 3.8324\n",
      "Epoch 8/150\n",
      "500/500 [==============================] - 0s 65us/step - loss: 2.9041 - mse: 2.9041\n",
      "Epoch 9/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 3.7269 - mse: 3.7269\n",
      "Epoch 10/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 2.5069 - mse: 2.5069\n",
      "Epoch 11/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 2.9881 - mse: 2.9881\n",
      "Epoch 12/150\n",
      "500/500 [==============================] - 0s 55us/step - loss: 3.1644 - mse: 3.1644\n",
      "Epoch 13/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 2.8622 - mse: 2.8622\n",
      "Epoch 14/150\n",
      "500/500 [==============================] - 0s 54us/step - loss: 2.5576 - mse: 2.5576\n",
      "Epoch 15/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 2.9792 - mse: 2.9792\n",
      "Epoch 16/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 2.6615 - mse: 2.6615\n",
      "Epoch 17/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 2.4379 - mse: 2.4379\n",
      "Epoch 18/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 2.9013 - mse: 2.9013\n",
      "Epoch 19/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 2.2237 - mse: 2.2237\n",
      "Epoch 20/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 2.4730 - mse: 2.4730\n",
      "Epoch 21/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 2.7047 - mse: 2.7047\n",
      "Epoch 22/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 2.7600 - mse: 2.7600\n",
      "Epoch 23/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 2.8273 - mse: 2.8273\n",
      "Epoch 24/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 2.7595 - mse: 2.7595\n",
      "Epoch 25/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 2.8040 - mse: 2.8040\n",
      "Epoch 26/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 2.1839 - mse: 2.1839\n",
      "Epoch 27/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 3.1459 - mse: 3.1459\n",
      "Epoch 28/150\n",
      "500/500 [==============================] - 0s 34us/step - loss: 2.4473 - mse: 2.4473\n",
      "Epoch 29/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 2.3981 - mse: 2.3981\n",
      "Epoch 30/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 2.2011 - mse: 2.2011\n",
      "Epoch 31/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 2.7748 - mse: 2.7748\n",
      "Epoch 32/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 2.3610 - mse: 2.3610\n",
      "Epoch 33/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 1.6884 - mse: 1.6884\n",
      "Epoch 34/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.8192 - mse: 1.8192\n",
      "Epoch 35/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 2.6518 - mse: 2.6518\n",
      "Epoch 36/150\n",
      "500/500 [==============================] - 0s 33us/step - loss: 2.0844 - mse: 2.0844\n",
      "Epoch 37/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 2.0870 - mse: 2.0870\n",
      "Epoch 38/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 1.8554 - mse: 1.8554\n",
      "Epoch 39/150\n",
      "500/500 [==============================] - 0s 34us/step - loss: 3.5146 - mse: 3.5146\n",
      "Epoch 40/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 2.0460 - mse: 2.0460\n",
      "Epoch 41/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 2.0748 - mse: 2.0748\n",
      "Epoch 42/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 1.8955 - mse: 1.8955\n",
      "Epoch 43/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 2.1513 - mse: 2.1513\n",
      "Epoch 44/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 2.0699 - mse: 2.0699\n",
      "Epoch 45/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 1.8972 - mse: 1.8972\n",
      "Epoch 46/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 2.2904 - mse: 2.2904\n",
      "Epoch 47/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 2.4333 - mse: 2.4333\n",
      "Epoch 48/150\n",
      "500/500 [==============================] - 0s 53us/step - loss: 1.8790 - mse: 1.8790\n",
      "Epoch 49/150\n",
      "500/500 [==============================] - 0s 64us/step - loss: 1.8876 - mse: 1.8876\n",
      "Epoch 50/150\n",
      "500/500 [==============================] - 0s 64us/step - loss: 1.9877 - mse: 1.9877\n",
      "Epoch 51/150\n",
      "500/500 [==============================] - 0s 70us/step - loss: 2.0126 - mse: 2.0126\n",
      "Epoch 52/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 1.9965 - mse: 1.9965\n",
      "Epoch 53/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 2.0544 - mse: 2.0544\n",
      "Epoch 54/150\n",
      "500/500 [==============================] - 0s 74us/step - loss: 1.9158 - mse: 1.9158\n",
      "Epoch 55/150\n",
      "500/500 [==============================] - 0s 81us/step - loss: 1.8637 - mse: 1.8637\n",
      "Epoch 56/150\n",
      "500/500 [==============================] - 0s 58us/step - loss: 1.8918 - mse: 1.8918\n",
      "Epoch 57/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 1.8681 - mse: 1.8681\n",
      "Epoch 58/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 1.7298 - mse: 1.7298\n",
      "Epoch 59/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.5825 - mse: 1.5825\n",
      "Epoch 60/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 1.7512 - mse: 1.7512\n",
      "Epoch 61/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 1.5142 - mse: 1.5142\n",
      "Epoch 62/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.6404 - mse: 1.6404\n",
      "Epoch 63/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 2.7282 - mse: 2.7282\n",
      "Epoch 64/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 2.0345 - mse: 2.0345\n",
      "Epoch 65/150\n",
      "500/500 [==============================] - 0s 55us/step - loss: 1.7391 - mse: 1.7391\n",
      "Epoch 66/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 1.7132 - mse: 1.7132\n",
      "Epoch 67/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 2.3251 - mse: 2.3251\n",
      "Epoch 68/150\n",
      "500/500 [==============================] - 0s 58us/step - loss: 2.0046 - mse: 2.0046\n",
      "Epoch 69/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 1.8984 - mse: 1.8984\n",
      "Epoch 70/150\n",
      "500/500 [==============================] - 0s 57us/step - loss: 1.4015 - mse: 1.4015\n",
      "Epoch 71/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.5835 - mse: 1.5835\n",
      "Epoch 72/150\n",
      "500/500 [==============================] - 0s 64us/step - loss: 1.9205 - mse: 1.9205\n",
      "Epoch 73/150\n",
      "500/500 [==============================] - 0s 66us/step - loss: 1.6171 - mse: 1.6171\n",
      "Epoch 74/150\n",
      "500/500 [==============================] - 0s 66us/step - loss: 1.3699 - mse: 1.3699\n",
      "Epoch 75/150\n",
      "500/500 [==============================] - 0s 63us/step - loss: 1.5299 - mse: 1.5299\n",
      "Epoch 76/150\n",
      "500/500 [==============================] - 0s 62us/step - loss: 1.3744 - mse: 1.3744\n",
      "Epoch 77/150\n",
      "500/500 [==============================] - 0s 59us/step - loss: 1.5728 - mse: 1.5728\n",
      "Epoch 78/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 1.7638 - mse: 1.7638\n",
      "Epoch 79/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 2.2749 - mse: 2.2749\n",
      "Epoch 80/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 1.8030 - mse: 1.8030\n",
      "Epoch 81/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 1.7530 - mse: 1.7530\n",
      "Epoch 82/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.3538 - mse: 1.3538\n",
      "Epoch 83/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 1.5295 - mse: 1.5295\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 38us/step - loss: 1.2893 - mse: 1.2893\n",
      "Epoch 85/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 2.6344 - mse: 2.6344\n",
      "Epoch 86/150\n",
      "500/500 [==============================] - 0s 54us/step - loss: 1.8980 - mse: 1.8980\n",
      "Epoch 87/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 1.6867 - mse: 1.6867\n",
      "Epoch 88/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 1.6792 - mse: 1.6792\n",
      "Epoch 89/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.3043 - mse: 1.3043\n",
      "Epoch 90/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 1.4020 - mse: 1.4020\n",
      "Epoch 91/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.6982 - mse: 1.6982\n",
      "Epoch 92/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.2176 - mse: 1.2176\n",
      "Epoch 93/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 1.9906 - mse: 1.9906\n",
      "Epoch 94/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 1.5451 - mse: 1.5451\n",
      "Epoch 95/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 1.7081 - mse: 1.7081\n",
      "Epoch 96/150\n",
      "500/500 [==============================] - 0s 55us/step - loss: 1.4907 - mse: 1.4907\n",
      "Epoch 97/150\n",
      "500/500 [==============================] - 0s 58us/step - loss: 1.6417 - mse: 1.6417\n",
      "Epoch 98/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 1.1455 - mse: 1.1455\n",
      "Epoch 99/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 1.2824 - mse: 1.2824\n",
      "Epoch 100/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 1.3053 - mse: 1.3053\n",
      "Epoch 101/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 1.3281 - mse: 1.3281\n",
      "Epoch 102/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 1.4152 - mse: 1.4152\n",
      "Epoch 103/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 1.4630 - mse: 1.4630\n",
      "Epoch 104/150\n",
      "500/500 [==============================] - 0s 35us/step - loss: 1.1913 - mse: 1.1913\n",
      "Epoch 105/150\n",
      "500/500 [==============================] - 0s 33us/step - loss: 1.9688 - mse: 1.9688\n",
      "Epoch 106/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 1.2986 - mse: 1.2986\n",
      "Epoch 107/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 1.4659 - mse: 1.4659\n",
      "Epoch 108/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.8391 - mse: 1.8391\n",
      "Epoch 109/150\n",
      "500/500 [==============================] - 0s 35us/step - loss: 1.3897 - mse: 1.3897\n",
      "Epoch 110/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 1.2382 - mse: 1.2382\n",
      "Epoch 111/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 1.2972 - mse: 1.2972\n",
      "Epoch 112/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 1.2084 - mse: 1.2084\n",
      "Epoch 113/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 1.3883 - mse: 1.3883\n",
      "Epoch 114/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 1.2130 - mse: 1.2130\n",
      "Epoch 115/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 1.1991 - mse: 1.1991\n",
      "Epoch 116/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.4076 - mse: 1.4076\n",
      "Epoch 117/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.2330 - mse: 1.2330\n",
      "Epoch 118/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.5556 - mse: 1.5556\n",
      "Epoch 119/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.2803 - mse: 1.2803\n",
      "Epoch 120/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.0201 - mse: 1.0201\n",
      "Epoch 121/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 1.1934 - mse: 1.1934\n",
      "Epoch 122/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 1.4170 - mse: 1.4170\n",
      "Epoch 123/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 1.2604 - mse: 1.2604\n",
      "Epoch 124/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 1.4247 - mse: 1.4247\n",
      "Epoch 125/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.3581 - mse: 1.3581\n",
      "Epoch 126/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 1.3971 - mse: 1.3971\n",
      "Epoch 127/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 1.6725 - mse: 1.6725\n",
      "Epoch 128/150\n",
      "500/500 [==============================] - 0s 36us/step - loss: 1.0715 - mse: 1.0715\n",
      "Epoch 129/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.9482 - mse: 0.9482\n",
      "Epoch 130/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.1531 - mse: 1.1531\n",
      "Epoch 131/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 1.2642 - mse: 1.2642\n",
      "Epoch 132/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.2857 - mse: 1.2857\n",
      "Epoch 133/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 1.0211 - mse: 1.0211\n",
      "Epoch 134/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 1.0206 - mse: 1.0206\n",
      "Epoch 135/150\n",
      "500/500 [==============================] - 0s 54us/step - loss: 1.0916 - mse: 1.0916\n",
      "Epoch 136/150\n",
      "500/500 [==============================] - 0s 66us/step - loss: 0.9745 - mse: 0.9745\n",
      "Epoch 137/150\n",
      "500/500 [==============================] - 0s 92us/step - loss: 1.3895 - mse: 1.3895\n",
      "Epoch 138/150\n",
      "500/500 [==============================] - 0s 98us/step - loss: 1.0763 - mse: 1.0763\n",
      "Epoch 139/150\n",
      "500/500 [==============================] - 0s 134us/step - loss: 1.5569 - mse: 1.5569\n",
      "Epoch 140/150\n",
      "500/500 [==============================] - 0s 94us/step - loss: 1.2204 - mse: 1.2204\n",
      "Epoch 141/150\n",
      "500/500 [==============================] - 0s 58us/step - loss: 1.1169 - mse: 1.1169\n",
      "Epoch 142/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 1.1109 - mse: 1.1109\n",
      "Epoch 143/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 1.1510 - mse: 1.1510\n",
      "Epoch 144/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.1692 - mse: 1.1692\n",
      "Epoch 145/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 1.1687 - mse: 1.1687\n",
      "Epoch 146/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.9912 - mse: 0.9912\n",
      "Epoch 147/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 1.0646 - mse: 1.0646\n",
      "Epoch 148/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 1.0395 - mse: 1.0395\n",
      "Epoch 149/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 1.2205 - mse: 1.2205\n",
      "Epoch 150/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.9365 - mse: 0.9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff2bcf47320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Input(27,(27,)))\n",
    "# model.add(Dense(500, activation='relu'))\n",
    "# model.add(Dropout(0.01))\n",
    "# model.add(Dense(300, activation='relu'))\n",
    "# model.add(Dropout(0.01))\n",
    "# model.add(Dense(200, activation='relu'))\n",
    "# model.add(Dropout(0.01))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "sgd = keras.optimizers.sgd(lr=0.04, decay=1e-6, nesterov=True)\n",
    "model.compile(optimizer='Nadam', loss='mse', metrics=['mse'])\n",
    "model.fit(X_train, Y_train,shuffle = True, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 206us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.056642738978068, 2.056642770767212]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.523373 ],\n",
       "       [14.860101 ],\n",
       "       [14.720882 ],\n",
       "       [10.480209 ],\n",
       "       [18.534214 ],\n",
       "       [13.764498 ],\n",
       "       [16.295448 ],\n",
       "       [16.545086 ],\n",
       "       [12.536541 ],\n",
       "       [12.398182 ],\n",
       "       [15.621747 ],\n",
       "       [13.503    ],\n",
       "       [12.449905 ],\n",
       "       [13.023948 ],\n",
       "       [12.496104 ],\n",
       "       [12.690403 ],\n",
       "       [11.027398 ],\n",
       "       [14.939812 ],\n",
       "       [15.767708 ],\n",
       "       [13.160051 ],\n",
       "       [12.20541  ],\n",
       "       [16.615744 ],\n",
       "       [17.624748 ],\n",
       "       [11.131349 ],\n",
       "       [15.086812 ],\n",
       "       [14.00772  ],\n",
       "       [17.720364 ],\n",
       "       [15.336315 ],\n",
       "       [12.291423 ],\n",
       "       [14.884138 ],\n",
       "       [15.624068 ],\n",
       "       [14.341858 ],\n",
       "       [14.392754 ],\n",
       "       [14.56068  ],\n",
       "       [14.642533 ],\n",
       "       [18.451283 ],\n",
       "       [12.19931  ],\n",
       "       [14.991621 ],\n",
       "       [14.670151 ],\n",
       "       [12.711942 ],\n",
       "       [15.097467 ],\n",
       "       [16.100172 ],\n",
       "       [17.050432 ],\n",
       "       [17.238907 ],\n",
       "       [13.180929 ],\n",
       "       [12.848316 ],\n",
       "       [11.856438 ],\n",
       "       [14.837683 ],\n",
       "       [15.376183 ],\n",
       "       [14.413251 ],\n",
       "       [14.47234  ],\n",
       "       [13.931414 ],\n",
       "       [17.584938 ],\n",
       "       [17.652279 ],\n",
       "       [15.193057 ],\n",
       "       [15.738512 ],\n",
       "       [14.877154 ],\n",
       "       [12.459156 ],\n",
       "       [17.236132 ],\n",
       "       [13.666227 ],\n",
       "       [13.027273 ],\n",
       "       [13.002398 ],\n",
       "       [17.777134 ],\n",
       "       [17.837484 ],\n",
       "       [11.959688 ],\n",
       "       [13.324717 ],\n",
       "       [14.594969 ],\n",
       "       [13.268985 ],\n",
       "       [16.196714 ],\n",
       "       [18.720913 ],\n",
       "       [15.226242 ],\n",
       "       [16.13178  ],\n",
       "       [15.0436735],\n",
       "       [12.762782 ],\n",
       "       [13.445449 ],\n",
       "       [14.591924 ],\n",
       "       [13.789482 ],\n",
       "       [14.9247465],\n",
       "       [14.060526 ],\n",
       "       [13.447113 ],\n",
       "       [16.852488 ],\n",
       "       [17.20031  ],\n",
       "       [17.25215  ],\n",
       "       [18.895657 ],\n",
       "       [17.711712 ],\n",
       "       [14.661219 ],\n",
       "       [15.061912 ],\n",
       "       [16.34492  ],\n",
       "       [17.582668 ],\n",
       "       [15.181374 ],\n",
       "       [17.471287 ],\n",
       "       [14.366375 ],\n",
       "       [17.241264 ],\n",
       "       [13.511932 ],\n",
       "       [18.04898  ],\n",
       "       [13.381147 ],\n",
       "       [17.463322 ],\n",
       "       [13.005704 ],\n",
       "       [16.064253 ],\n",
       "       [13.029675 ],\n",
       "       [12.205517 ],\n",
       "       [11.886959 ],\n",
       "       [13.741142 ],\n",
       "       [14.536465 ],\n",
       "       [14.488964 ],\n",
       "       [13.887104 ],\n",
       "       [15.477619 ],\n",
       "       [16.432915 ],\n",
       "       [11.29019  ],\n",
       "       [15.227304 ],\n",
       "       [12.382925 ],\n",
       "       [16.44969  ],\n",
       "       [14.871407 ],\n",
       "       [13.190724 ],\n",
       "       [11.012666 ],\n",
       "       [13.543577 ],\n",
       "       [16.479462 ],\n",
       "       [14.224476 ],\n",
       "       [13.246446 ],\n",
       "       [14.538413 ],\n",
       "       [17.46784  ],\n",
       "       [13.051167 ],\n",
       "       [13.218157 ],\n",
       "       [12.844954 ],\n",
       "       [12.487091 ],\n",
       "       [13.358325 ],\n",
       "       [16.98246  ],\n",
       "       [13.385117 ],\n",
       "       [15.712764 ],\n",
       "       [18.271137 ],\n",
       "       [ 9.910563 ],\n",
       "       [11.925392 ],\n",
       "       [11.317827 ],\n",
       "       [15.864947 ],\n",
       "       [16.86333  ],\n",
       "       [16.53991  ],\n",
       "       [15.656797 ],\n",
       "       [15.914322 ],\n",
       "       [15.423786 ],\n",
       "       [14.0844755],\n",
       "       [15.1123705],\n",
       "       [17.230753 ],\n",
       "       [11.330051 ],\n",
       "       [11.854889 ],\n",
       "       [14.949236 ],\n",
       "       [ 9.071831 ],\n",
       "       [11.957454 ],\n",
       "       [13.078817 ],\n",
       "       [ 9.925838 ],\n",
       "       [11.342382 ],\n",
       "       [10.342771 ],\n",
       "       [ 9.598842 ],\n",
       "       [12.542217 ],\n",
       "       [10.283938 ],\n",
       "       [16.172113 ],\n",
       "       [10.973937 ],\n",
       "       [11.686682 ],\n",
       "       [13.327724 ],\n",
       "       [17.475536 ],\n",
       "       [12.158955 ],\n",
       "       [10.763003 ],\n",
       "       [17.000778 ],\n",
       "       [14.754426 ],\n",
       "       [15.431236 ],\n",
       "       [13.641663 ],\n",
       "       [11.591394 ],\n",
       "       [13.542538 ],\n",
       "       [15.853233 ],\n",
       "       [11.07341  ],\n",
       "       [11.391132 ],\n",
       "       [17.20558  ],\n",
       "       [13.83279  ],\n",
       "       [14.036013 ],\n",
       "       [16.021845 ],\n",
       "       [15.870819 ],\n",
       "       [16.164251 ],\n",
       "       [13.224142 ],\n",
       "       [15.661298 ],\n",
       "       [15.419542 ],\n",
       "       [14.713445 ],\n",
       "       [18.349003 ],\n",
       "       [16.178804 ],\n",
       "       [14.952789 ],\n",
       "       [13.263734 ],\n",
       "       [12.015615 ],\n",
       "       [13.779218 ],\n",
       "       [12.101825 ],\n",
       "       [12.900204 ],\n",
       "       [12.904336 ],\n",
       "       [13.368937 ],\n",
       "       [11.463001 ],\n",
       "       [13.345041 ],\n",
       "       [12.930504 ],\n",
       "       [16.291222 ],\n",
       "       [10.50199  ],\n",
       "       [ 7.9336658],\n",
       "       [11.650465 ],\n",
       "       [12.672085 ],\n",
       "       [12.002754 ],\n",
       "       [12.995377 ],\n",
       "       [12.195848 ],\n",
       "       [13.095274 ],\n",
       "       [13.200888 ],\n",
       "       [17.09174  ],\n",
       "       [15.935869 ],\n",
       "       [16.427952 ],\n",
       "       [16.405125 ],\n",
       "       [ 8.785942 ],\n",
       "       [14.8025465],\n",
       "       [17.147427 ],\n",
       "       [10.221981 ],\n",
       "       [13.207712 ],\n",
       "       [16.754906 ],\n",
       "       [16.073044 ],\n",
       "       [13.660055 ],\n",
       "       [14.618487 ],\n",
       "       [16.51638  ],\n",
       "       [15.0072565],\n",
       "       [15.275715 ],\n",
       "       [15.422693 ],\n",
       "       [17.366013 ],\n",
       "       [15.0296955],\n",
       "       [12.125736 ],\n",
       "       [16.352333 ],\n",
       "       [16.493643 ],\n",
       "       [18.85162  ],\n",
       "       [13.577094 ],\n",
       "       [16.540958 ],\n",
       "       [15.590307 ],\n",
       "       [15.214934 ],\n",
       "       [15.214934 ],\n",
       "       [17.16991  ],\n",
       "       [18.006477 ],\n",
       "       [15.721682 ],\n",
       "       [13.357109 ],\n",
       "       [16.024643 ],\n",
       "       [17.249397 ],\n",
       "       [13.008888 ],\n",
       "       [14.911825 ],\n",
       "       [17.906078 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 500 samples, validate on 362 samples\n",
      "Epoch 1/150\n",
      "500/500 [==============================] - 0s 253us/step - loss: 2.8134 - accuracy: 0.6620 - val_loss: 1.3594 - val_accuracy: 0.7459\n",
      "Epoch 2/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 1.6808 - accuracy: 0.5860 - val_loss: 1.2520 - val_accuracy: 0.5967\n",
      "Epoch 3/150\n",
      "500/500 [==============================] - 0s 66us/step - loss: 1.5134 - accuracy: 0.5380 - val_loss: 1.2537 - val_accuracy: 0.5829\n",
      "Epoch 4/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 1.4853 - accuracy: 0.5400 - val_loss: 1.1894 - val_accuracy: 0.6133\n",
      "Epoch 5/150\n",
      "500/500 [==============================] - 0s 57us/step - loss: 1.4605 - accuracy: 0.5520 - val_loss: 1.1802 - val_accuracy: 0.6022\n",
      "Epoch 6/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.4368 - accuracy: 0.5520 - val_loss: 1.1638 - val_accuracy: 0.6022\n",
      "Epoch 7/150\n",
      "500/500 [==============================] - 0s 62us/step - loss: 1.4046 - accuracy: 0.5400 - val_loss: 1.1084 - val_accuracy: 0.6381\n",
      "Epoch 8/150\n",
      "500/500 [==============================] - 0s 56us/step - loss: 1.3796 - accuracy: 0.5640 - val_loss: 1.0931 - val_accuracy: 0.6354\n",
      "Epoch 9/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.3522 - accuracy: 0.5540 - val_loss: 1.0583 - val_accuracy: 0.6492\n",
      "Epoch 10/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 1.3243 - accuracy: 0.5700 - val_loss: 1.1237 - val_accuracy: 0.5912\n",
      "Epoch 11/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.2933 - accuracy: 0.5520 - val_loss: 1.0345 - val_accuracy: 0.6326\n",
      "Epoch 12/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 1.2668 - accuracy: 0.5680 - val_loss: 1.0132 - val_accuracy: 0.6326\n",
      "Epoch 13/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 1.2346 - accuracy: 0.5800 - val_loss: 1.0860 - val_accuracy: 0.5773\n",
      "Epoch 14/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 1.2075 - accuracy: 0.5580 - val_loss: 0.9642 - val_accuracy: 0.6409\n",
      "Epoch 15/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 1.1816 - accuracy: 0.5800 - val_loss: 0.9460 - val_accuracy: 0.6354\n",
      "Epoch 16/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 1.1570 - accuracy: 0.5880 - val_loss: 0.9629 - val_accuracy: 0.6050\n",
      "Epoch 17/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 1.1298 - accuracy: 0.5860 - val_loss: 0.9468 - val_accuracy: 0.6022\n",
      "Epoch 18/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.1023 - accuracy: 0.5680 - val_loss: 0.9372 - val_accuracy: 0.6022\n",
      "Epoch 19/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 1.0744 - accuracy: 0.5900 - val_loss: 0.8909 - val_accuracy: 0.6215\n",
      "Epoch 20/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 1.0534 - accuracy: 0.5880 - val_loss: 0.8650 - val_accuracy: 0.6326\n",
      "Epoch 21/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 1.0238 - accuracy: 0.5960 - val_loss: 0.8388 - val_accuracy: 0.6354\n",
      "Epoch 22/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.9996 - accuracy: 0.6000 - val_loss: 0.8936 - val_accuracy: 0.5801\n",
      "Epoch 23/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.9896 - accuracy: 0.5880 - val_loss: 0.8648 - val_accuracy: 0.5939\n",
      "Epoch 24/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.9566 - accuracy: 0.5900 - val_loss: 0.8089 - val_accuracy: 0.6133\n",
      "Epoch 25/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.9351 - accuracy: 0.5940 - val_loss: 0.7916 - val_accuracy: 0.6188\n",
      "Epoch 26/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.9113 - accuracy: 0.6180 - val_loss: 0.8278 - val_accuracy: 0.5939\n",
      "Epoch 27/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.8944 - accuracy: 0.6020 - val_loss: 0.7369 - val_accuracy: 0.6436\n",
      "Epoch 28/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.8741 - accuracy: 0.6240 - val_loss: 0.7681 - val_accuracy: 0.5967\n",
      "Epoch 29/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.8545 - accuracy: 0.6200 - val_loss: 0.7638 - val_accuracy: 0.5967\n",
      "Epoch 30/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.8377 - accuracy: 0.6160 - val_loss: 0.7784 - val_accuracy: 0.6050\n",
      "Epoch 31/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.8231 - accuracy: 0.6020 - val_loss: 0.6946 - val_accuracy: 0.6436\n",
      "Epoch 32/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.8055 - accuracy: 0.6340 - val_loss: 0.7362 - val_accuracy: 0.6133\n",
      "Epoch 33/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.7897 - accuracy: 0.6280 - val_loss: 0.7138 - val_accuracy: 0.6243\n",
      "Epoch 34/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.7707 - accuracy: 0.6400 - val_loss: 0.7193 - val_accuracy: 0.6133\n",
      "Epoch 35/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.7577 - accuracy: 0.6340 - val_loss: 0.6879 - val_accuracy: 0.6354\n",
      "Epoch 36/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.7433 - accuracy: 0.6360 - val_loss: 0.6544 - val_accuracy: 0.6657\n",
      "Epoch 37/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.7357 - accuracy: 0.6320 - val_loss: 0.6561 - val_accuracy: 0.6630\n",
      "Epoch 38/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.7143 - accuracy: 0.6420 - val_loss: 0.6602 - val_accuracy: 0.6575\n",
      "Epoch 39/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.7027 - accuracy: 0.6460 - val_loss: 0.6891 - val_accuracy: 0.6326\n",
      "Epoch 40/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6922 - accuracy: 0.6460 - val_loss: 0.6686 - val_accuracy: 0.6519\n",
      "Epoch 41/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.6881 - accuracy: 0.6660 - val_loss: 0.6473 - val_accuracy: 0.6657\n",
      "Epoch 42/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.6702 - accuracy: 0.6700 - val_loss: 0.6497 - val_accuracy: 0.6602\n",
      "Epoch 43/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6544 - accuracy: 0.6640 - val_loss: 0.5791 - val_accuracy: 0.7238\n",
      "Epoch 44/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.6527 - accuracy: 0.6560 - val_loss: 0.6853 - val_accuracy: 0.6077\n",
      "Epoch 45/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.6446 - accuracy: 0.6620 - val_loss: 0.6769 - val_accuracy: 0.6077\n",
      "Epoch 46/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6324 - accuracy: 0.6720 - val_loss: 0.6342 - val_accuracy: 0.6492\n",
      "Epoch 47/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.6234 - accuracy: 0.6620 - val_loss: 0.7367 - val_accuracy: 0.5580\n",
      "Epoch 48/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.6176 - accuracy: 0.6700 - val_loss: 0.5993 - val_accuracy: 0.6906\n",
      "Epoch 49/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.6056 - accuracy: 0.6780 - val_loss: 0.5581 - val_accuracy: 0.7376\n",
      "Epoch 50/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.6045 - accuracy: 0.6800 - val_loss: 0.5928 - val_accuracy: 0.6796\n",
      "Epoch 51/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.5961 - accuracy: 0.6700 - val_loss: 0.6274 - val_accuracy: 0.6381\n",
      "Epoch 52/150\n",
      "500/500 [==============================] - 0s 37us/step - loss: 0.5885 - accuracy: 0.6760 - val_loss: 0.6535 - val_accuracy: 0.6188\n",
      "Epoch 53/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.5827 - accuracy: 0.6780 - val_loss: 0.5961 - val_accuracy: 0.6575\n",
      "Epoch 54/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.5800 - accuracy: 0.6820 - val_loss: 0.6218 - val_accuracy: 0.6409\n",
      "Epoch 55/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.5715 - accuracy: 0.6800 - val_loss: 0.5650 - val_accuracy: 0.6934\n",
      "Epoch 56/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.5680 - accuracy: 0.6860 - val_loss: 0.6047 - val_accuracy: 0.6575\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 43us/step - loss: 0.5639 - accuracy: 0.6860 - val_loss: 0.5961 - val_accuracy: 0.6657\n",
      "Epoch 58/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 0.5601 - accuracy: 0.6900 - val_loss: 0.6090 - val_accuracy: 0.6657\n",
      "Epoch 59/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.5567 - accuracy: 0.6920 - val_loss: 0.5765 - val_accuracy: 0.6740\n",
      "Epoch 60/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.5527 - accuracy: 0.7000 - val_loss: 0.5679 - val_accuracy: 0.6823\n",
      "Epoch 61/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.5466 - accuracy: 0.7000 - val_loss: 0.5885 - val_accuracy: 0.6740\n",
      "Epoch 62/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.5433 - accuracy: 0.6980 - val_loss: 0.6203 - val_accuracy: 0.6630\n",
      "Epoch 63/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.5451 - accuracy: 0.7060 - val_loss: 0.5971 - val_accuracy: 0.6685\n",
      "Epoch 64/150\n",
      "500/500 [==============================] - 0s 65us/step - loss: 0.5363 - accuracy: 0.7060 - val_loss: 0.5774 - val_accuracy: 0.6823\n",
      "Epoch 65/150\n",
      "500/500 [==============================] - 0s 57us/step - loss: 0.5389 - accuracy: 0.7020 - val_loss: 0.6366 - val_accuracy: 0.6519\n",
      "Epoch 66/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 0.5331 - accuracy: 0.6940 - val_loss: 0.5801 - val_accuracy: 0.6768\n",
      "Epoch 67/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 0.5263 - accuracy: 0.7000 - val_loss: 0.5617 - val_accuracy: 0.6989\n",
      "Epoch 68/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.5259 - accuracy: 0.6900 - val_loss: 0.5502 - val_accuracy: 0.7099\n",
      "Epoch 69/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.5236 - accuracy: 0.7060 - val_loss: 0.5886 - val_accuracy: 0.6740\n",
      "Epoch 70/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.5204 - accuracy: 0.7100 - val_loss: 0.6439 - val_accuracy: 0.6354\n",
      "Epoch 71/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.5189 - accuracy: 0.7220 - val_loss: 0.5385 - val_accuracy: 0.7238\n",
      "Epoch 72/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.5175 - accuracy: 0.7080 - val_loss: 0.5415 - val_accuracy: 0.7238\n",
      "Epoch 73/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.5147 - accuracy: 0.7140 - val_loss: 0.5695 - val_accuracy: 0.7017\n",
      "Epoch 74/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.5120 - accuracy: 0.7160 - val_loss: 0.5548 - val_accuracy: 0.7155\n",
      "Epoch 75/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.5134 - accuracy: 0.7140 - val_loss: 0.6150 - val_accuracy: 0.6519\n",
      "Epoch 76/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.5105 - accuracy: 0.7120 - val_loss: 0.5341 - val_accuracy: 0.7459\n",
      "Epoch 77/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.5088 - accuracy: 0.7120 - val_loss: 0.5929 - val_accuracy: 0.6713\n",
      "Epoch 78/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.5060 - accuracy: 0.7160 - val_loss: 0.6097 - val_accuracy: 0.6575\n",
      "Epoch 79/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.5076 - accuracy: 0.7180 - val_loss: 0.5264 - val_accuracy: 0.7376\n",
      "Epoch 80/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.5026 - accuracy: 0.7080 - val_loss: 0.5878 - val_accuracy: 0.6796\n",
      "Epoch 81/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.5010 - accuracy: 0.7220 - val_loss: 0.5135 - val_accuracy: 0.7348\n",
      "Epoch 82/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.5031 - accuracy: 0.7260 - val_loss: 0.5523 - val_accuracy: 0.7238\n",
      "Epoch 83/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.4978 - accuracy: 0.7100 - val_loss: 0.5949 - val_accuracy: 0.6657\n",
      "Epoch 84/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.4990 - accuracy: 0.7160 - val_loss: 0.6205 - val_accuracy: 0.6436\n",
      "Epoch 85/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.5010 - accuracy: 0.7180 - val_loss: 0.5566 - val_accuracy: 0.7099\n",
      "Epoch 86/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4940 - accuracy: 0.7160 - val_loss: 0.5413 - val_accuracy: 0.7265\n",
      "Epoch 87/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.4932 - accuracy: 0.7180 - val_loss: 0.5439 - val_accuracy: 0.7320\n",
      "Epoch 88/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.4921 - accuracy: 0.7180 - val_loss: 0.5973 - val_accuracy: 0.6685\n",
      "Epoch 89/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.4926 - accuracy: 0.7280 - val_loss: 0.6063 - val_accuracy: 0.6713\n",
      "Epoch 90/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.4965 - accuracy: 0.7260 - val_loss: 0.5791 - val_accuracy: 0.6796\n",
      "Epoch 91/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.4939 - accuracy: 0.7260 - val_loss: 0.5526 - val_accuracy: 0.7127\n",
      "Epoch 92/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4906 - accuracy: 0.7280 - val_loss: 0.4858 - val_accuracy: 0.7652\n",
      "Epoch 93/150\n",
      "500/500 [==============================] - 0s 39us/step - loss: 0.4934 - accuracy: 0.7400 - val_loss: 0.5241 - val_accuracy: 0.7431\n",
      "Epoch 94/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.4879 - accuracy: 0.7360 - val_loss: 0.4861 - val_accuracy: 0.7597\n",
      "Epoch 95/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.4901 - accuracy: 0.7260 - val_loss: 0.5547 - val_accuracy: 0.7044\n",
      "Epoch 96/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4885 - accuracy: 0.7260 - val_loss: 0.5106 - val_accuracy: 0.7597\n",
      "Epoch 97/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.4879 - accuracy: 0.7200 - val_loss: 0.5485 - val_accuracy: 0.7127\n",
      "Epoch 98/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.4848 - accuracy: 0.7440 - val_loss: 0.5018 - val_accuracy: 0.7680\n",
      "Epoch 99/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.4845 - accuracy: 0.7360 - val_loss: 0.5800 - val_accuracy: 0.6823\n",
      "Epoch 100/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.4867 - accuracy: 0.7340 - val_loss: 0.5373 - val_accuracy: 0.7293\n",
      "Epoch 101/150\n",
      "500/500 [==============================] - 0s 55us/step - loss: 0.4825 - accuracy: 0.7260 - val_loss: 0.5852 - val_accuracy: 0.6851\n",
      "Epoch 102/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4823 - accuracy: 0.7360 - val_loss: 0.5781 - val_accuracy: 0.6878\n",
      "Epoch 103/150\n",
      "500/500 [==============================] - 0s 54us/step - loss: 0.4849 - accuracy: 0.7240 - val_loss: 0.5978 - val_accuracy: 0.6768\n",
      "Epoch 104/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4841 - accuracy: 0.7280 - val_loss: 0.5030 - val_accuracy: 0.7652\n",
      "Epoch 105/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.4825 - accuracy: 0.7500 - val_loss: 0.5692 - val_accuracy: 0.6961\n",
      "Epoch 106/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.4800 - accuracy: 0.7320 - val_loss: 0.6084 - val_accuracy: 0.6713\n",
      "Epoch 107/150\n",
      "500/500 [==============================] - 0s 56us/step - loss: 0.4800 - accuracy: 0.7460 - val_loss: 0.5712 - val_accuracy: 0.6934\n",
      "Epoch 108/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 0.4823 - accuracy: 0.7520 - val_loss: 0.5837 - val_accuracy: 0.6906\n",
      "Epoch 109/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.4822 - accuracy: 0.7420 - val_loss: 0.4792 - val_accuracy: 0.7790\n",
      "Epoch 110/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.4822 - accuracy: 0.7440 - val_loss: 0.5686 - val_accuracy: 0.6906\n",
      "Epoch 111/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.4855 - accuracy: 0.7180 - val_loss: 0.5973 - val_accuracy: 0.6851\n",
      "Epoch 112/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.4799 - accuracy: 0.7400 - val_loss: 0.5666 - val_accuracy: 0.6906\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 44us/step - loss: 0.4840 - accuracy: 0.7340 - val_loss: 0.4944 - val_accuracy: 0.7707\n",
      "Epoch 114/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.4799 - accuracy: 0.7360 - val_loss: 0.6587 - val_accuracy: 0.6381\n",
      "Epoch 115/150\n",
      "500/500 [==============================] - 0s 38us/step - loss: 0.4792 - accuracy: 0.7460 - val_loss: 0.5506 - val_accuracy: 0.7265\n",
      "Epoch 116/150\n",
      "500/500 [==============================] - 0s 40us/step - loss: 0.4772 - accuracy: 0.7340 - val_loss: 0.6092 - val_accuracy: 0.6768\n",
      "Epoch 117/150\n",
      "500/500 [==============================] - 0s 41us/step - loss: 0.4780 - accuracy: 0.7420 - val_loss: 0.5770 - val_accuracy: 0.6878\n",
      "Epoch 118/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4829 - accuracy: 0.7300 - val_loss: 0.5605 - val_accuracy: 0.7099\n",
      "Epoch 119/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4739 - accuracy: 0.7340 - val_loss: 0.5475 - val_accuracy: 0.7293\n",
      "Epoch 120/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.4752 - accuracy: 0.7460 - val_loss: 0.4943 - val_accuracy: 0.7680\n",
      "Epoch 121/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 0.4762 - accuracy: 0.7360 - val_loss: 0.5620 - val_accuracy: 0.7099\n",
      "Epoch 122/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.4723 - accuracy: 0.7460 - val_loss: 0.5621 - val_accuracy: 0.7072\n",
      "Epoch 123/150\n",
      "500/500 [==============================] - 0s 52us/step - loss: 0.4769 - accuracy: 0.7400 - val_loss: 0.5714 - val_accuracy: 0.6989\n",
      "Epoch 124/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.4761 - accuracy: 0.7420 - val_loss: 0.5705 - val_accuracy: 0.7017\n",
      "Epoch 125/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.4756 - accuracy: 0.7480 - val_loss: 0.6470 - val_accuracy: 0.6575\n",
      "Epoch 126/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.4784 - accuracy: 0.7300 - val_loss: 0.5644 - val_accuracy: 0.7099\n",
      "Epoch 127/150\n",
      "500/500 [==============================] - 0s 45us/step - loss: 0.4780 - accuracy: 0.7340 - val_loss: 0.5695 - val_accuracy: 0.6934\n",
      "Epoch 128/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4769 - accuracy: 0.7340 - val_loss: 0.4984 - val_accuracy: 0.7735\n",
      "Epoch 129/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4737 - accuracy: 0.7380 - val_loss: 0.5888 - val_accuracy: 0.6906\n",
      "Epoch 130/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4719 - accuracy: 0.7560 - val_loss: 0.5508 - val_accuracy: 0.7210\n",
      "Epoch 131/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4707 - accuracy: 0.7360 - val_loss: 0.6350 - val_accuracy: 0.6713\n",
      "Epoch 132/150\n",
      "500/500 [==============================] - 0s 44us/step - loss: 0.4732 - accuracy: 0.7440 - val_loss: 0.5283 - val_accuracy: 0.7431\n",
      "Epoch 133/150\n",
      "500/500 [==============================] - 0s 42us/step - loss: 0.4778 - accuracy: 0.7420 - val_loss: 0.5127 - val_accuracy: 0.7597\n",
      "Epoch 134/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.4766 - accuracy: 0.7280 - val_loss: 0.5378 - val_accuracy: 0.7403\n",
      "Epoch 135/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4733 - accuracy: 0.7300 - val_loss: 0.5816 - val_accuracy: 0.7017\n",
      "Epoch 136/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.4723 - accuracy: 0.7360 - val_loss: 0.6306 - val_accuracy: 0.6740\n",
      "Epoch 137/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.4712 - accuracy: 0.7340 - val_loss: 0.6071 - val_accuracy: 0.6823\n",
      "Epoch 138/150\n",
      "500/500 [==============================] - 0s 50us/step - loss: 0.4714 - accuracy: 0.7480 - val_loss: 0.5430 - val_accuracy: 0.7376\n",
      "Epoch 139/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.4739 - accuracy: 0.7440 - val_loss: 0.5289 - val_accuracy: 0.7459\n",
      "Epoch 140/150\n",
      "500/500 [==============================] - 0s 47us/step - loss: 0.4723 - accuracy: 0.7460 - val_loss: 0.5374 - val_accuracy: 0.7459\n",
      "Epoch 141/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.4707 - accuracy: 0.7520 - val_loss: 0.5603 - val_accuracy: 0.7155\n",
      "Epoch 142/150\n",
      "500/500 [==============================] - 0s 54us/step - loss: 0.4709 - accuracy: 0.7400 - val_loss: 0.5586 - val_accuracy: 0.7155\n",
      "Epoch 143/150\n",
      "500/500 [==============================] - 0s 51us/step - loss: 0.4692 - accuracy: 0.7480 - val_loss: 0.5810 - val_accuracy: 0.6934\n",
      "Epoch 144/150\n",
      "500/500 [==============================] - 0s 46us/step - loss: 0.4699 - accuracy: 0.7420 - val_loss: 0.5504 - val_accuracy: 0.7265\n",
      "Epoch 145/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4735 - accuracy: 0.7260 - val_loss: 0.5610 - val_accuracy: 0.7072\n",
      "Epoch 146/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4692 - accuracy: 0.7460 - val_loss: 0.5738 - val_accuracy: 0.7017\n",
      "Epoch 147/150\n",
      "500/500 [==============================] - 0s 43us/step - loss: 0.4701 - accuracy: 0.7380 - val_loss: 0.5325 - val_accuracy: 0.7486\n",
      "Epoch 148/150\n",
      "500/500 [==============================] - 0s 57us/step - loss: 0.4681 - accuracy: 0.7460 - val_loss: 0.6147 - val_accuracy: 0.6768\n",
      "Epoch 149/150\n",
      "500/500 [==============================] - 0s 49us/step - loss: 0.4687 - accuracy: 0.7440 - val_loss: 0.5883 - val_accuracy: 0.6961\n",
      "Epoch 150/150\n",
      "500/500 [==============================] - 0s 48us/step - loss: 0.4713 - accuracy: 0.7380 - val_loss: 0.5484 - val_accuracy: 0.7348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff2bb655470>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "# model.add(Input(27,(27,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.01))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "sgd = keras.optimizers.sgd(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(optimizer='Nadam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.fit(X_train2, Y_train2,validation_data=(X_test2, Y_test2),shuffle = True, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 47us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5843262553215027, 0.7208333611488342]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test,Y_test22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3713065 ],\n",
       "       [0.57082057],\n",
       "       [0.83289254],\n",
       "       [0.36247298],\n",
       "       [0.9418326 ],\n",
       "       [0.38771242],\n",
       "       [0.9186348 ],\n",
       "       [0.91759336],\n",
       "       [0.28540304],\n",
       "       [0.7631109 ],\n",
       "       [0.9814571 ],\n",
       "       [0.7782095 ],\n",
       "       [0.21097073],\n",
       "       [0.6025854 ],\n",
       "       [0.45909438],\n",
       "       [0.85442066],\n",
       "       [0.6740418 ],\n",
       "       [0.73454046],\n",
       "       [0.87694377],\n",
       "       [0.49938992],\n",
       "       [0.51378006],\n",
       "       [0.92923236],\n",
       "       [0.92479384],\n",
       "       [0.72187465],\n",
       "       [0.6710008 ],\n",
       "       [0.47813854],\n",
       "       [0.93870527],\n",
       "       [0.7628336 ],\n",
       "       [0.7621751 ],\n",
       "       [0.7589353 ],\n",
       "       [0.90232354],\n",
       "       [0.4471941 ],\n",
       "       [0.7528678 ],\n",
       "       [0.7786143 ],\n",
       "       [0.57607585],\n",
       "       [0.87495476],\n",
       "       [0.52045715],\n",
       "       [0.7639358 ],\n",
       "       [0.7944355 ],\n",
       "       [0.89505893],\n",
       "       [0.6507562 ],\n",
       "       [0.8225949 ],\n",
       "       [0.9574471 ],\n",
       "       [0.8969085 ],\n",
       "       [0.5305984 ],\n",
       "       [0.7057246 ],\n",
       "       [0.5124979 ],\n",
       "       [0.800784  ],\n",
       "       [0.8887075 ],\n",
       "       [0.67191786],\n",
       "       [0.96460444],\n",
       "       [0.8629035 ],\n",
       "       [0.94046926],\n",
       "       [0.980791  ],\n",
       "       [0.8976193 ],\n",
       "       [0.90592206],\n",
       "       [0.5085331 ],\n",
       "       [0.602905  ],\n",
       "       [0.98184264],\n",
       "       [0.5077993 ],\n",
       "       [0.4034659 ],\n",
       "       [0.6107946 ],\n",
       "       [0.92975926],\n",
       "       [0.9784405 ],\n",
       "       [0.6526962 ],\n",
       "       [0.67100143],\n",
       "       [0.5786296 ],\n",
       "       [0.6767057 ],\n",
       "       [0.8126302 ],\n",
       "       [0.98628914],\n",
       "       [0.8135901 ],\n",
       "       [0.7215951 ],\n",
       "       [0.8707645 ],\n",
       "       [0.6321931 ],\n",
       "       [0.85061526],\n",
       "       [0.95933616],\n",
       "       [0.7393681 ],\n",
       "       [0.83568186],\n",
       "       [0.30180657],\n",
       "       [0.61005294],\n",
       "       [0.85119194],\n",
       "       [0.95180124],\n",
       "       [0.792186  ],\n",
       "       [0.9778334 ],\n",
       "       [0.9580066 ],\n",
       "       [0.78207684],\n",
       "       [0.7351013 ],\n",
       "       [0.9271932 ],\n",
       "       [0.9537128 ],\n",
       "       [0.66954213],\n",
       "       [0.8218778 ],\n",
       "       [0.9810113 ],\n",
       "       [0.7607819 ],\n",
       "       [0.46731567],\n",
       "       [0.9529438 ],\n",
       "       [0.5228125 ],\n",
       "       [0.8825187 ],\n",
       "       [0.51278573],\n",
       "       [0.7804974 ],\n",
       "       [0.5046903 ],\n",
       "       [0.52977735],\n",
       "       [0.3743459 ],\n",
       "       [0.7370715 ],\n",
       "       [0.53286207],\n",
       "       [0.49960396],\n",
       "       [0.2326077 ],\n",
       "       [0.9672695 ],\n",
       "       [0.96534824],\n",
       "       [0.3804995 ],\n",
       "       [0.87009466],\n",
       "       [0.22260818],\n",
       "       [0.97545785],\n",
       "       [0.8371033 ],\n",
       "       [0.1701102 ],\n",
       "       [0.5251563 ],\n",
       "       [0.60037464],\n",
       "       [0.66391903],\n",
       "       [0.52824414],\n",
       "       [0.2861275 ],\n",
       "       [0.712516  ],\n",
       "       [0.9760249 ],\n",
       "       [0.56856287],\n",
       "       [0.77039504],\n",
       "       [0.62086946],\n",
       "       [0.19228984],\n",
       "       [0.6565428 ],\n",
       "       [0.9113125 ],\n",
       "       [0.53310895],\n",
       "       [0.731184  ],\n",
       "       [0.9273888 ],\n",
       "       [0.4945597 ],\n",
       "       [0.54785895],\n",
       "       [0.49669522],\n",
       "       [0.91689175],\n",
       "       [0.67144305],\n",
       "       [0.92356306],\n",
       "       [0.8864576 ],\n",
       "       [0.8541882 ],\n",
       "       [0.8462137 ],\n",
       "       [0.68579966],\n",
       "       [0.83044875],\n",
       "       [0.5103296 ],\n",
       "       [0.19166681],\n",
       "       [0.46485695],\n",
       "       [0.51749164],\n",
       "       [0.10055031],\n",
       "       [0.36443308],\n",
       "       [0.3957773 ],\n",
       "       [0.18749057],\n",
       "       [0.16370597],\n",
       "       [0.09839199],\n",
       "       [0.40192127],\n",
       "       [0.29169938],\n",
       "       [0.15837598],\n",
       "       [0.7798258 ],\n",
       "       [0.10071499],\n",
       "       [0.18067889],\n",
       "       [0.4096934 ],\n",
       "       [0.9255826 ],\n",
       "       [0.11342999],\n",
       "       [0.2766583 ],\n",
       "       [0.86281604],\n",
       "       [0.5121159 ],\n",
       "       [0.72170854],\n",
       "       [0.173507  ],\n",
       "       [0.13590652],\n",
       "       [0.17107017],\n",
       "       [0.9093334 ],\n",
       "       [0.224499  ],\n",
       "       [0.08623745],\n",
       "       [0.64066523],\n",
       "       [0.8025739 ],\n",
       "       [0.75188273],\n",
       "       [0.15403534],\n",
       "       [0.20399791],\n",
       "       [0.5368099 ],\n",
       "       [0.53160846],\n",
       "       [0.65590286],\n",
       "       [0.8769264 ],\n",
       "       [0.49632353],\n",
       "       [0.9102669 ],\n",
       "       [0.7350685 ],\n",
       "       [0.18943441],\n",
       "       [0.47398216],\n",
       "       [0.13617638],\n",
       "       [0.36768353],\n",
       "       [0.14731799],\n",
       "       [0.17055388],\n",
       "       [0.16746892],\n",
       "       [0.24776936],\n",
       "       [0.07548211],\n",
       "       [0.21688494],\n",
       "       [0.24119207],\n",
       "       [0.6826013 ],\n",
       "       [0.06874744],\n",
       "       [0.02167627],\n",
       "       [0.12473903],\n",
       "       [0.09444699],\n",
       "       [0.19894609],\n",
       "       [0.18661965],\n",
       "       [0.11171081],\n",
       "       [0.19196105],\n",
       "       [0.23765865],\n",
       "       [0.8937913 ],\n",
       "       [0.6586838 ],\n",
       "       [0.83014905],\n",
       "       [0.6204207 ],\n",
       "       [0.09679265],\n",
       "       [0.51710826],\n",
       "       [0.48917228],\n",
       "       [0.32181844],\n",
       "       [0.5664343 ],\n",
       "       [0.64204556],\n",
       "       [0.60726446],\n",
       "       [0.20309952],\n",
       "       [0.5100386 ],\n",
       "       [0.76714176],\n",
       "       [0.6799943 ],\n",
       "       [0.56837064],\n",
       "       [0.46935067],\n",
       "       [0.8480734 ],\n",
       "       [0.526749  ],\n",
       "       [0.15334675],\n",
       "       [0.9071795 ],\n",
       "       [0.5116022 ],\n",
       "       [0.86041147],\n",
       "       [0.191798  ],\n",
       "       [0.70519376],\n",
       "       [0.41972312],\n",
       "       [0.43551677],\n",
       "       [0.43551677],\n",
       "       [0.6576199 ],\n",
       "       [0.87012845],\n",
       "       [0.49939278],\n",
       "       [0.31983635],\n",
       "       [0.5748817 ],\n",
       "       [0.83243334],\n",
       "       [0.24235697],\n",
       "       [0.3454821 ],\n",
       "       [0.72638375]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 if n > 0.5 else 0 for n in model2.predict(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
